
# Purpose

The learning API is a natural continuation of the UCI Tracker in regards to tune and evolve the evaluation function
by the chess knowledge inside the existing expert games, captured by UCI tracker. 

The implemented supervised learning is called Gold Middle tuning algorithm, because of the idea, which it implements.
It works very similar to feed forward NNs with 1 layer and liner activation function.
Just tune weights of list of features and sums them.
For example: 0.9 * material + 0.5 * mobility + 1.1 * king safety + ...
Its ideal is to check the sign of the expected evaluation of the position (generated by SF14.1 as example) minus actual evaluation of own evaluation function.
Than the algorithm accumulates all changes - millions of +1 and -1.
The goal is to make the counts of +1 and -1 equal for each feature and moves the weights up and down accordingly. This is why the algorithm is called Gold Middle.
At the end of each tuning iteration, the weights are multiplied by weight, so next time the error / delta between both evaluations will be smaller.

#See also

https://github.com/bagaturchess/Bagatur/issues/16